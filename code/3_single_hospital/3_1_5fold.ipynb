{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Image path\n",
    "image_folder = \"/local/data1/honzh073/data/8bit_downsample\"\n",
    "\n",
    "# CSV path\n",
    "csv_file_path = \"/local/data1/honzh073/local_repo/FL/code/3_single_hospital/csv_files/image_data.csv\"\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    # Define the CSV header fields\n",
    "    fieldnames = ['HospitalID', 'PatientID', 'ImageID', 'ImagePath', 'Label']\n",
    "    \n",
    "    # Create a CSV writer object and write the header\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Iterate through files in the folder\n",
    "    for filename in sorted(os.listdir(image_folder)):\n",
    "        # Construct the complete image file path\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "\n",
    "        # Parse the filename to extract HospitalID, PatientID, image number, and image label\n",
    "        parts = filename.split('_')\n",
    "        hospital_id = parts[3]\n",
    "        patient_id = parts[1]\n",
    "        image_number = parts[6]\n",
    "        image_label = parts[4]\n",
    "\n",
    "        # Write data into the CSV file\n",
    "        writer.writerow({\n",
    "            'HospitalID': hospital_id,\n",
    "            'PatientID': patient_id,\n",
    "            'ImageID': image_number,\n",
    "            'ImagePath': image_path,\n",
    "            'Label': image_label\n",
    "        })\n",
    "\n",
    "# Print a message indicating that the CSV file has been created and saved\n",
    "print(\"CSV file has been created and saved to:\", csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据、验证数据和测试数据已经生成并保存到 train.csv, val.csv 和 test.csv。\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# 指定特定的医院ID\n",
    "target_hospital_id = '43'  # 替换成你想要选择的医院ID\n",
    "\n",
    "# 读取原始CSV文件并筛选特定医院ID的数据\n",
    "input_csv_path = \"/local/data1/honzh073/local_repo/FL/code/3_single_hospital/csv_files/image_data.csv\"\n",
    "patient_data = defaultdict(list)\n",
    "\n",
    "with open(input_csv_path, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if row['HospitalID'] == target_hospital_id:\n",
    "            patient_id = row['PatientID']\n",
    "            patient_data[patient_id].append(row)\n",
    "\n",
    "# 计算患者ID的数量\n",
    "num_patients = len(patient_data)\n",
    "\n",
    "# 计算划分的数量\n",
    "num_train = int(num_patients * 0.7)\n",
    "# num_val = int(num_patients * 0.3)\n",
    "num_test = num_patients - num_train\n",
    "\n",
    "# 获取随机选择的患者ID\n",
    "all_patient_ids = list(patient_data.keys())\n",
    "random.shuffle(all_patient_ids)\n",
    "\n",
    "# 划分数据集\n",
    "train_patients = all_patient_ids[:num_train]\n",
    "# val_patients = all_patient_ids[num_train:num_train + num_val]\n",
    "test_patients = all_patient_ids[num_train:]\n",
    "\n",
    "# 用于存储划分后的数据\n",
    "train_data = []\n",
    "val_data = []\n",
    "test_data = []\n",
    "\n",
    "# 遍历按照患者ID分组的数据，并将数据划分到对应的数据集中\n",
    "for patient_id, images in patient_data.items():\n",
    "    if patient_id in train_patients:\n",
    "        train_data.extend(images)\n",
    "    # elif patient_id in val_patients:\n",
    "    #     val_data.extend(images)\n",
    "    elif patient_id in test_patients:\n",
    "        test_data.extend(images)\n",
    "\n",
    "# 将数据集写入CSV文件\n",
    "def write_to_csv(file_path, data):\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=data[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "write_to_csv('/local/data1/honzh073/local_repo/FL/code/3_single_hospital/csv_files/k_fold_train.csv', train_data)\n",
    "# write_to_csv('/local/data1/honzh073/local_repo/FL/code/3_single_hospital/csv_files/val.csv', val_data)\n",
    "write_to_csv('/local/data1/honzh073/local_repo/FL/code/3_single_hospital/csv_files/k_fold_test.csv', test_data)\n",
    "\n",
    "print(\"训练数据、验证数据和测试数据已经生成并保存到 train.csv, val.csv 和 test.csv。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import csv\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "def get_classweight(train_dataset):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # aff and nff numbers in training dataset\n",
    "    train_nff_count = sum(1 for _, label in train_dataset if label == 0)  # 0 NFF\n",
    "    train_aff_count = sum(1 for _, label in train_dataset if label == 1)  # 1 AFF\n",
    "\n",
    "    class_weight_nff = 1 / (2 * (train_nff_count / (train_nff_count + train_aff_count)))\n",
    "    class_weight_aff = 1 / (2 * (train_aff_count / (train_nff_count + train_aff_count)))\n",
    "    \n",
    "    return [class_weight_nff, class_weight_aff]   \n",
    "    \n",
    "def train_model(train_loader, validation_loader, classweight, num_epochs, lr, step_size, gamma, model_name, device):\n",
    "\n",
    "    # Load pre-trained model\n",
    "    torch.hub.set_dir('/local/data1/honzh073/download/TORCH_PRETRAINED')\n",
    "    if model_name == 'resnet152':\n",
    "        from torchvision.models import resnet152, ResNet152_Weights\n",
    "        model = models.resnet152(weights=ResNet152_Weights.DEFAULT)\n",
    "        \n",
    "    elif model_name == 'densenet161':\n",
    "        from torchvision.models import densenet161, DenseNet161_Weights\n",
    "        model = models.densenet161(weights=DenseNet161_Weights.DEFAULT)\n",
    "        \n",
    "    elif model_name == 'resnet50':\n",
    "        from torchvision.models import resnet50, ResNet50_Weights\n",
    "        model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "    elif model_name == 'vgg19':\n",
    "        from torchvision.models import vgg19, VGG19_Weights\n",
    "        model = models.vgg19(weights=VGG19_Weights.DEFAULT)\n",
    "\n",
    "    elif model_name == 'resnet101':\n",
    "        from torchvision.models import resnet101, ResNet101_Weights\n",
    "        model = models.resnet101(weights=ResNet101_Weights.DEFAULT)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type. 'vgg19' 'resnet50' 'resnet101' 'resnet152' or 'densenet161'.\")\n",
    "\n",
    "    # Modify the output layer\n",
    "    num_classes = 2\n",
    "    if model_name == 'densenet161':\n",
    "        in_features = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(in_features, num_classes)\n",
    "    else:\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    # Move model to the specified device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.Tensor(classweight).to(device))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    \n",
    "    # Training (loss and accuracy)\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "    train_accuracies = []\n",
    "    validation_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        \n",
    "        model.eval()\n",
    "        correct_validation = 0\n",
    "        total_validation = 0\n",
    "        validation_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in validation_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_validation += labels.size(0)\n",
    "                correct_validation += (predicted == labels).sum().item()\n",
    "                validation_loss += loss.item()\n",
    "        \n",
    "        # validation accuracy and loss\n",
    "        validation_accuracy = 100 * correct_validation / total_validation\n",
    "        validation_loss /= len(validation_loader)\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        validation_losses.append(validation_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        validation_accuracies.append(validation_accuracy)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "            f\"Train Loss: {loss.item():.4f}, \"\n",
    "            f\"Validation Loss: {validation_loss:.4f}, \"\n",
    "            f\"Train Acc: {train_accuracy:.2f}%, \"\n",
    "            f\"Validation Acc: {validation_accuracy:.2f}%\")\n",
    "        \n",
    "        scheduler.step()  # Step the learning rate scheduler\n",
    "\n",
    "    # Plot loss and accuracy\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(validation_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(validation_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend() \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model(model, test_dataset, batch_size, device):\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    model.eval()\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    test_loss = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_accuracy = 100 * correct_test / total_test\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.2f}%\")\n",
    "\n",
    "    # confusion matrix\n",
    "    with torch.no_grad():\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    auc_score = roc_auc_score(all_labels, all_predictions)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "    \n",
    "    # Precision、Recall、F1 Score\n",
    "    class_labels = {0: 'NFF', 1: 'AFF'}  # Define your class labels here\n",
    "\n",
    "    # Then, when you create the confusion matrix and classification report, use these labels:\n",
    "    classification_rep = classification_report(all_labels, all_predictions, target_names=[class_labels[i] for i in range(len(class_labels))])\n",
    "    print(\"AUC:\", auc_score)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_rep)\n",
    "\n",
    "    plot_roc_curve(all_labels, all_predictions)\n",
    "    \n",
    "def plot_roc_curve(all_labels, all_predictions):\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_predictions)\n",
    "    roc_auc = roc_auc_score(all_labels, all_predictions)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import csv\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = []\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 读取CSV文件\n",
    "        with open(csv_file, 'r') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                image_path = row['ImagePath']\n",
    "                label = row['Label']\n",
    "                # 如果Label是‘NFF’，定义为0；如果label是‘AFF’，定义为1\n",
    "                if label == 'NFF':\n",
    "                    label = 0\n",
    "                elif label == 'AFF':\n",
    "                    label = 1\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid label in CSV file.\")\n",
    "                self.data.append((image_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.data[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define data augmentation transforms for training data\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平翻转\n",
    "    transforms.RandomVerticalFlip(),    # 随机垂直翻转\n",
    "    transforms.RandomRotation(degrees=15),  # 随机旋转（范围：-15度到+15度）\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # 色彩抖动\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # 随机尺寸裁剪\n",
    "    transforms.ToTensor(),  # 转换为Tensor\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229]),  # 标准化（仅一个通道）\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Define transform for validation and test data\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "# 创建训练数据集\n",
    "train_dataset = CustomDataset('/local/data1/honzh073/local_repo/FL/code/3_single_hospital/csv_files/train.csv', transform=train_transform)\n",
    "val_dataset = CustomDataset('/local/data1/honzh073/local_repo/FL/code/3_single_hospital/csv_files/val.csv', transform=test_transform)\n",
    "test_dataset = CustomDataset('/local/data1/honzh073/local_repo/FL/code/3_single_hospital/csv_files/test.csv', transform=test_transform)\n",
    "\n",
    "repeated_dataset = torch.utils.data.ConcatDataset([train_dataset] * 20)\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(repeated_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# classweight\n",
    "classweight = get_classweight(train_dataset)\n",
    "print(classweight)\n",
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(dataset, num_images=5):\n",
    "    # Get some random indices from the dataset\n",
    "    random_indices = np.random.choice(len(dataset), num_images, replace=False)\n",
    "\n",
    "    # Plot images with truncated names\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        image, label = dataset[idx]  # Use the dataset directly\n",
    "        filename = dataset.data[idx][0]  # Get the filename from dataset's internal data attribute\n",
    "        truncated_filename = filename.split('/')[-1][:15]  # Extract the last part and truncate to 15 characters\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.title(f\"Label: {label}\")\n",
    "        # plt.imshow(image[0],cmap='gray')  # Assuming single-channel (grayscale) image\n",
    "        plt.imshow(image[0])  # Assuming single-channel (grayscale) image\n",
    "\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_image(train_dataset, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50\n",
    "resnet50 = train_model(train_loader, val_loader,\n",
    "                       classweight=classweight,\n",
    "                       num_epochs=50, \n",
    "                       lr=0.00001, step_size=10, gamma=0.1,\n",
    "                       device=device,\n",
    "                       model_name='resnet50')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model=resnet50, test_dataset=test_dataset, batch_size=batch_size, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet101\n",
    "resnet101 = train_model(train_loader, val_loader, classweight, num_epochs=50, lr=0.0001, step_size=10, gamma=0.1, model_name='resnet101', device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model=resnet101, test_dataset=test_dataset, batch_size=batch_size, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet152\n",
    "resnet152 = train_model(train_loader, validation_loader, classweight, \n",
    "                        num_epochs=50, lr=0.0001, step_size=10, gamma=0.1, model_name='resnet152', device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model=resnet152, test_dataset=test_dataset, batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# densenet161\n",
    "densenet161 = train_model(train_loader, validation_loader, classweight, \n",
    "                          num_epochs=50, lr=0.0001, step_size=10, gamma=0.1, model_name='densenet161', device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model=densenet161, test_dataset=test_dataset, batch_size=batch_size, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
