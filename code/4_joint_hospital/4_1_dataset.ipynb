{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create train val and test dataset\n",
    "# import os\n",
    "# import random\n",
    "# import shutil\n",
    "\n",
    "# # 原始数据集根文件夹\n",
    "# dataset_root = '/local/data1/honzh073/data/hospital_43&55'\n",
    "\n",
    "# # 目标数据集文件夹\n",
    "# target_dataset_folder = '/local/data1/honzh073/data/hospital_43&55_dataset'\n",
    "\n",
    "# # 创建目标数据集文件夹\n",
    "# os.makedirs(target_dataset_folder, exist_ok=True)\n",
    "\n",
    "# # AFF和NFF文件夹\n",
    "# fracture_types = ['AFF', 'NFF']\n",
    "\n",
    "# # 分割数据集的比例\n",
    "# train_ratio = 0.7\n",
    "# val_ratio = 0.3\n",
    "\n",
    "# # 遍历AFF和NFF文件夹\n",
    "# for fracture_type in fracture_types:\n",
    "#     source_folder = os.path.join(dataset_root, fracture_type)\n",
    "#     patients = os.listdir(source_folder)\n",
    "    \n",
    "#     # 随机打乱患者顺序\n",
    "#     random.shuffle(patients)\n",
    "    \n",
    "#     # 划分数据集\n",
    "#     total_patients = len(patients)\n",
    "#     train_end = int(total_patients * train_ratio)\n",
    "    \n",
    "#     train_patients = patients[:train_end]\n",
    "#     val_patients = patients[train_end:]\n",
    "    \n",
    "#     # 复制图片到相应的数据集文件夹\n",
    "#     for patient_id in train_patients:\n",
    "#         source_path = os.path.join(source_folder, patient_id)\n",
    "#         target_path = os.path.join(target_dataset_folder, 'train', fracture_type, patient_id)\n",
    "#         shutil.copytree(source_path, target_path)\n",
    "    \n",
    "#     for patient_id in val_patients:\n",
    "#         source_path = os.path.join(source_folder, patient_id)\n",
    "#         target_path = os.path.join(target_dataset_folder, 'val', fracture_type, patient_id)\n",
    "#         shutil.copytree(source_path, target_path)\n",
    "    \n",
    "\n",
    "\n",
    "# print(\"Dataset split completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.models as models\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "# Augmentation\n",
    "# Define data augmentation transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),  # Randomly rotate the image up to 30 degrees\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3),  # Adjust color\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random affine transformation\n",
    "    transforms.RandomPerspective(),  # Random perspective transformation\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Random resized crop\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the image to RGB\n",
    "])\n",
    "\n",
    "# Define the data loaders\n",
    "train_dataset = ImageFolder(root='/local/data1/honzh073/data/hospital_43&55_dataset/train', transform=transform)\n",
    "validation_dataset = ImageFolder(root='/local/data1/honzh073/data/hospital_43&55_dataset/val', transform=transform)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    device = torch.device(\"cuda:0\")  # Use GPU 0\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some random indices from the validation dataset\n",
    "random_indices = np.random.choice(len(validation_dataset), 5, replace=False)\n",
    "\n",
    "# Print image file paths\n",
    "for i, idx in enumerate(random_indices):\n",
    "    filename = validation_dataset.samples[idx][0]  # Get the filename\n",
    "    print(f\"Image {i + 1} Path: {filename}\")\n",
    "\n",
    "# Plot images (transformed) with truncated names\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, idx in enumerate(random_indices):\n",
    "    image, label = validation_dataset[idx]  # Use validation_dataset directly\n",
    "    filename = validation_dataset.samples[idx][0]  # Get the filename\n",
    "    truncated_filename = filename.split('/')[-1][:15]  # Extract the last part and truncate to 15 characters\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    # plt.imshow(image[0], cmap='gray')  # Single-channel (grayscale)\n",
    "    plt.imshow(image[0])  # Single-channel (grayscale)\n",
    "\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------\n",
    "import os\n",
    "\n",
    "def count_number(path_folder):\n",
    "    # AFF和NFF文件夹路径\n",
    "    aff_folder = os.path.join(path_folder, 'AFF')\n",
    "    nff_folder = os.path.join(path_folder, 'NFF')\n",
    "\n",
    "    # 统计AFF和NFF文件夹中的图片数量\n",
    "    aff_image_count = sum(len(files) for _, _, files in os.walk(aff_folder))\n",
    "    nff_image_count = sum(len(files) for _, _, files in os.walk(nff_folder))\n",
    "    \n",
    "    return aff_image_count, nff_image_count\n",
    "\n",
    "print('total:')\n",
    "path_folder = '/local/data1/honzh073/data/hospital_43&55'\n",
    "total_aff_num, total_nff_num = count_number(path_folder)\n",
    "print('aff number:', total_aff_num, '; nff number:', total_nff_num)\n",
    "\n",
    "print('train:')\n",
    "path_folder = '/local/data1/honzh073/data/hospital_43&55_dataset/train'\n",
    "aff_num, nff_num = count_number(path_folder)\n",
    "print('aff number:', aff_num, '; nff number:', nff_num)\n",
    "print('%:', aff_num / total_aff_num , '; %:', nff_num / total_nff_num)\n",
    "\n",
    "print('val:')\n",
    "path_folder = '/local/data1/honzh073/data/hospital_43&55_dataset/val'\n",
    "aff_num, nff_num = count_number(path_folder)\n",
    "print('aff number:', aff_num, '; nff number:', nff_num)\n",
    "print('%:', aff_num / total_aff_num , '; %:', nff_num / total_nff_num)\n",
    "\n",
    "\n",
    "\n",
    "# aff and nff numbers in training dataset\n",
    "train_aff_count = sum(1 for _, label in train_dataset if label == 0)  # 0 AFF\n",
    "train_nff_count = sum(1 for _, label in train_dataset if label == 1)  # 1 NFF\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# Calculate class weights\n",
    "n_aff_train = train_aff_count\n",
    "n_nff_train = train_nff_count\n",
    "\n",
    "class_weight_aff = 1 / (2 * (n_aff_train / (n_aff_train + n_nff_train)))\n",
    "class_weight_nff = 1 / (2 * (n_nff_train / (n_aff_train + n_nff_train)))\n",
    "\n",
    "print(f\"Class Weight for AFF (0): {class_weight_aff:.4f}\")\n",
    "print(f\"Class Weight for NFF (1): {class_weight_nff:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet152, ResNet152_Weights\n",
    "# from torch.utils.tensorboard import SummaryWriter  # 导入TensorBoard的SummaryWriter\n",
    "import torch\n",
    "\n",
    "# 设置预训练模型的下载目录\n",
    "torch.hub.set_dir('/local/data1/honzh073/download/TORCH_PRETRAINED')\n",
    "\n",
    "# 这将把预训练模型下载到指定的目录\n",
    "\n",
    "\n",
    "\n",
    "# Settings\n",
    "lr = 0.0001\n",
    "step_size = 10\n",
    "gamma = 0.1\n",
    "\n",
    "# Class weights\n",
    "class_weights = [class_weight_aff, class_weight_nff]\n",
    "class_weights = torch.Tensor(class_weights).to(device)\n",
    "\n",
    "# ResNet152\n",
    "model = models.resnet152(weights=ResNet152_Weights.DEFAULT)\n",
    "model = model.to(device)\n",
    "\n",
    "# Update the output layer\n",
    "model.fc = nn.Linear(2048, 2)  # output layer classes number = dataset classes number\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "# Training (loss and accuracy)\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "train_accuracies = []\n",
    "validation_accuracies = []\n",
    "\n",
    "# writer = SummaryWriter('logs')\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    \n",
    "    model.eval()\n",
    "    correct_validation = 0\n",
    "    total_validation = 0\n",
    "    validation_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_validation += labels.size(0)\n",
    "            correct_validation += (predicted == labels).sum().item()\n",
    "            validation_loss += loss.item()\n",
    "    \n",
    "    validation_accuracy = 100 * correct_validation / total_validation\n",
    "    validation_loss /= len(validation_loader)\n",
    "    \n",
    "    train_losses.append(loss.item())\n",
    "    validation_losses.append(validation_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    validation_accuracies.append(validation_accuracy)\n",
    "    \n",
    "    # # 写入训练集的损失和准确度\n",
    "    # writer.add_scalar('Loss/train', loss.item(), epoch)\n",
    "    # writer.add_scalar('Accuracy/train', train_accuracy, epoch)\n",
    "\n",
    "    # # 写入验证集的损失和准确度\n",
    "    # writer.add_scalar('Loss/validation', validation_loss, epoch)\n",
    "    # writer.add_scalar('Accuracy/validation', validation_accuracy, epoch)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {loss.item():.4f}, Validation Loss: {validation_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Validation Acc: {validation_accuracy:.2f}%\")\n",
    "    \n",
    "    scheduler.step()  # Step the learning rate scheduler\n",
    "\n",
    "# Plot loss and accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(validation_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data loaders\n",
    "test_dataset = ImageFolder(root='/local/data1/honzh073/data/hospital_33', transform=transform)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "\n",
    "# Test dataset performance\n",
    "model.eval()\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "test_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        test_loss += loss.item()\n",
    "\n",
    "test_accuracy = 100 * correct_test / total_test\n",
    "test_loss /= len(test_loader)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.2f}%\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "original_classes = train_loader.dataset.classes\n",
    "\n",
    "# confusion matrix\n",
    "with torch.no_grad():\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# Precision、Recall、F1 Score\n",
    "classification_rep = classification_report(all_labels, all_predictions, target_names=original_classes)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
