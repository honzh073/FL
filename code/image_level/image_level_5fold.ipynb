{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "# Augmentation\n",
    "# Define data augmentation transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),  # Randomly rotate the image up to 30 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Adjust color\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random affine transformation\n",
    "    transforms.RandomPerspective(),  # Random perspective transformation\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Random resized crop\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    # transforms.Normalize(mean=[0.485], std=[0.229]) # gray scale, channels\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the image to RGB\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root='/local/data1/honzh073/model/data/8bit_dataset', transform=transform)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "# Random seed\n",
    "seed = 123\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Split dataset into 80% train, 20% test\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size], generator=torch.Generator().manual_seed(seed))\n",
    "\n",
    "# DataLoader for training and testing\n",
    "batch_size = 64\n",
    "\n",
    "# Move train_loader and test_loader to GPU\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    device = torch.device(\"cuda:0\") # we have GPU 0, 1\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "print('Dataset has been loaded!')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ---------------------------------------------------------------------------------\n",
    "# plot images from train dataset\n",
    "random_indices = np.random.choice(len(train_dataset), 5, replace=False)\n",
    "\n",
    "# Plot images (transformed)\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, idx in enumerate(random_indices):\n",
    "    image, label = train_dataset[idx]\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    # plt.imshow(image[0])  # 3-channel (RGB image)\n",
    "    plt.imshow(image[0], cmap='gray')  # single-channel (grayscale image)\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate Class Weights"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ---------------------------------------------------------------------------------\n",
    "# aff and nff numbers in training dataset\n",
    "train_aff_count = sum(1 for _, label in train_dataset if label == 0)  # 0 AFF\n",
    "train_nff_count = sum(1 for _, label in train_dataset if label == 1)  # 1 NFF\n",
    "\n",
    "# aff and nff numbers in test dataset\n",
    "test_aff_count = sum(1 for _, label in test_dataset if label == 0)\n",
    "test_nff_count = sum(1 for _, label in test_dataset if label == 1)\n",
    "\n",
    "print(f\"train aff number: {train_aff_count}\")\n",
    "print(f\"train nff number: {train_nff_count}\")\n",
    "print(f\"test aff number: {test_aff_count}\")\n",
    "print(f\"test nff number: {test_nff_count}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# Calculate class weights\n",
    "n_aff_train = train_aff_count\n",
    "n_nff_train = train_nff_count\n",
    "\n",
    "class_weight_aff = 1 / (2 * (n_aff_train / (n_aff_train + n_nff_train)))\n",
    "class_weight_nff = 1 / (2 * (n_nff_train / (n_aff_train + n_nff_train)))\n",
    "\n",
    "print(f\"Class Weight for AFF (0): {class_weight_aff:.4f}\")\n",
    "print(f\"Class Weight for NFF (1): {class_weight_nff:.4f}\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# class_weight_aff = 2.5203\n",
    "# class_weight_nff = 0.6237"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Before the Train Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from torchvision.models import resnet152, ResNet152_Weights\n",
    "\n",
    "# Move class weights to the selected device\n",
    "class_weights = torch.Tensor([class_weight_aff, class_weight_nff]).to(device)\n",
    "\n",
    "# ResNet18\n",
    "model = models.resnet152(weights=ResNet152_Weights.DEFAULT).to(device)\n",
    "\n",
    "# Update the output layer\n",
    "model.fc = nn.Linear(2048, 2)  # output layer classes number = dataset classes number\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# training and test\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        # Move images and labels to the selected device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # Move images and labels to the selected device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Test_Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.00001)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet18"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "# settings\n",
    "lr = 0.01\n",
    "step_size = 10\n",
    "gamma = 0.1\n",
    "\n",
    "# Move class weights to the selected device\n",
    "class_weights = [class_weight_aff, class_weight_nff]\n",
    "class_weights = torch.Tensor(class_weights).to(device)\n",
    "\n",
    "# ResNet18\n",
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(512, 2)  # output layer classes number = dataset classes number\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "\n",
    "# training and test\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    correct_train = 0  # Correct predictions during training\n",
    "    total_train = 0    # Total examples during training\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        # Move images and labels to the selected device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate training accuracy within this batch\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_accuracy = 100 * correct_train / total_train  # Calculate training accuracy\n",
    "\n",
    "    model.eval()\n",
    "    correct_test = 0   # Correct predictions during testing\n",
    "    total_test = 0     # Total examples during testing\n",
    "    test_loss = 0      # Variable to store test loss\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "            test_loss += criterion(outputs, labels).item()  # Accumulate test loss\n",
    "\n",
    "    # Calculate test accuracy\n",
    "    test_accuracy = 100 * correct_test / total_test\n",
    "\n",
    "    # Calculate average test loss\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    # Record training and test loss and accuracy\n",
    "    train_losses.append(loss.item())\n",
    "    test_losses.append(test_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {loss.item():.4f}, Test Loss: {test_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Test Acc: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Plot loss and accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save the trained VGG model\n",
    "# torch.save(model.state_dict(), 'resnet18_xray_classifier.pth')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet50\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "# settings\n",
    "lr = 0.001\n",
    "step_size = 10\n",
    "gamma = 0.1\n",
    "\n",
    "# Move class weights to the selected device\n",
    "class_weights = [class_weight_aff, class_weight_nff]\n",
    "class_weights = torch.Tensor(class_weights).to(device)\n",
    "\n",
    "# ResNet18\n",
    "model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Move the model to the selected device\n",
    "model = model.to(device)\n",
    "\n",
    "# Update the output layer\n",
    "model.fc = nn.Linear(2048, 2)  # output layer classes number = dataset classes number\n",
    "\n",
    "# Move the model and loss function to the selected device\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Move the loss function to the selected device\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "\n",
    "# training and test\n",
    "# Lists to store loss and accuracy values\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    correct_train = 0  # Correct predictions during training\n",
    "    total_train = 0    # Total examples during training\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        # Move images and labels to the selected device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate training accuracy within this batch\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_accuracy = 100 * correct_train / total_train  # Calculate training accuracy\n",
    "\n",
    "    model.eval()\n",
    "    correct_test = 0   # Correct predictions during testing\n",
    "    total_test = 0     # Total examples during testing\n",
    "    test_loss = 0      # Variable to store test loss\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # Move images and labels to the selected device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "            test_loss += criterion(outputs, labels).item()  # Accumulate test loss\n",
    "\n",
    "    # Calculate test accuracy\n",
    "    test_accuracy = 100 * correct_test / total_test\n",
    "\n",
    "    # Calculate average test loss\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    # Record training and test loss and accuracy\n",
    "    train_losses.append(loss.item())\n",
    "    test_losses.append(test_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {loss.item():.4f}, Test Loss: {test_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Test Acc: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Plot loss and accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# resNet50, Adam(model.parameters(), lr=0.00001)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save the trained VGG model\n",
    "# torch.save(model.state_dict(), 'resnet50_xray_classifier.pth')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet152"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import random\n",
    "import matplotlib.pyplot as plt  # Import Matplotlib for plotting\n",
    "from torchvision.models import resnet152, ResNet152_Weights\n",
    "\n",
    "# settings\n",
    "lr = 0.001\n",
    "step_size = 10\n",
    "gamma = 0.1\n",
    "\n",
    "# Move class weights to the selected device\n",
    "class_weights = [class_weight_aff, class_weight_nff]\n",
    "class_weights = torch.Tensor(class_weights).to(device)\n",
    "\n",
    "# ResNet18\n",
    "model = models.resnet152(weights=ResNet152_Weights.DEFAULT)\n",
    "model = model.to(device)\n",
    "\n",
    "# Update the output layer\n",
    "model.fc = nn.Linear(2048, 2)  # output layer classes number = dataset classes number\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "# training and test\n",
    "# Lists to store loss and accuracy values\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    correct_train = 0  # Correct predictions during training\n",
    "    total_train = 0    # Total examples during training\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        # Move images and labels to the selected device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate training accuracy within this batch\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_accuracy = 100 * correct_train / total_train  # Calculate training accuracy\n",
    "\n",
    "    model.eval()\n",
    "    correct_test = 0   # Correct predictions during testing\n",
    "    total_test = 0     # Total examples during testing\n",
    "    test_loss = 0      # Variable to store test loss\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # Move images and labels to the selected device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "            test_loss += criterion(outputs, labels).item()  # Accumulate test loss\n",
    "\n",
    "    # Calculate test accuracy\n",
    "    test_accuracy = 100 * correct_test / total_test\n",
    "\n",
    "    # Calculate average test loss\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    # Record training and test loss and accuracy\n",
    "    train_losses.append(loss.item())\n",
    "    test_losses.append(test_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {loss.item():.4f}, Test Loss: {test_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Test Acc: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Plot loss and accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# resNet50, Adam(model.parameters(), lr=0.00001)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/home/honzh073/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:327199)",
      "at w.execute (/home/honzh073/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:326520)",
      "at w.start (/home/honzh073/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:322336)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/honzh073/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:336863)",
      "at async t.CellExecutionQueue.start (/home/honzh073/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:336403)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save the trained VGG model\n",
    "# # torch.save(model.state_dict(), 'resnet152_xray_classifier.pth')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VGG19 large deep network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "from torchvision.models import vgg19, VGG19_Weights\n",
    "\n",
    "# Move class weights to the selected device\n",
    "class_weights = [class_weight_aff, class_weight_nff]\n",
    "class_weights = torch.Tensor(class_weights).to(device)\n",
    "\n",
    "# VGG19\n",
    "model = models.vgg19(weights=VGG19_Weights.DEFAULT)\n",
    "\n",
    "# Modify the classifier part for your specific number of classes\n",
    "model.classifier[6] = nn.Linear(4096, 2)  # output layer classes number = dataset classes number\n",
    "\n",
    "# Move the model to the selected device\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Move the loss function to the selected device\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# training and test\n",
    "# Lists to store loss and accuracy values\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    correct_train = 0  # Correct predictions during training\n",
    "    total_train = 0    # Total examples during training\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        # Move images and labels to the selected device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate training accuracy within this batch\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_accuracy = 100 * correct_train / total_train  # Calculate training accuracy\n",
    "\n",
    "    model.eval()\n",
    "    correct_test = 0   # Correct predictions during testing\n",
    "    total_test = 0     # Total examples during testing\n",
    "    test_loss = 0      # Variable to store test loss\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # Move images and labels to the selected device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "            test_loss += criterion(outputs, labels).item()  # Accumulate test loss\n",
    "\n",
    "    # Calculate test accuracy\n",
    "    test_accuracy = 100 * correct_test / total_test\n",
    "\n",
    "    # Calculate average test loss\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    # Record training and test loss and accuracy\n",
    "    train_losses.append(loss.item())\n",
    "    test_losses.append(test_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {loss.item():.4f}, Test Loss: {test_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Test Acc: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Plot loss and accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# weights=VGG19_Weights.DEFAULT\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save VGG model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save model\n",
    "# # torch.save(model.state_dict(), 'vgg19_xray_classifier.pth')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Resnet152 5-fold"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import KFold  # Import KFold for cross-validation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import random\n",
    "import matplotlib.pyplot as plt  # Import Matplotlib for plotting\n",
    "from torchvision.models import resnet152, ResNet152_Weights\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Move class weights to the selected device\n",
    "class_weights = [class_weight_aff, class_weight_nff]\n",
    "class_weights = torch.Tensor(class_weights).to(device)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# Create a KFold object to split the dataset\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracy and loss values for each fold\n",
    "fold_train_accuracies = []\n",
    "fold_test_accuracies = []\n",
    "fold_train_losses = []\n",
    "fold_test_losses = []\n",
    "\n",
    "for fold, (train_indices, test_indices) in enumerate(kf.split(dataset)):\n",
    "    print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "\n",
    "    # Split the dataset into train and test sets for this fold\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "    # Create data loaders for train and test sets\n",
    "    batch_size = 64\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    # ResNet152\n",
    "    model = models.resnet152(weights=ResNet152_Weights.DEFAULT)\n",
    "\n",
    "    # Update the output layer\n",
    "    model.fc = nn.Linear(2048, 2)  # output layer classes number = dataset classes number\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    # Lists to store loss and accuracy values\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    num_epochs = 25\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        correct_train = 0  # Correct predictions during training\n",
    "        total_train = 0    # Total examples during training\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            # Move images and labels to the selected device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate training accuracy within this batch\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = 100 * correct_train / total_train  # Calculate training accuracy\n",
    "\n",
    "        model.eval()\n",
    "        correct_test = 0   # Correct predictions during testing\n",
    "        total_test = 0     # Total examples during testing\n",
    "        test_loss = 0      # Variable to store test loss\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                # Move images and labels to the selected device\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "                test_loss += criterion(outputs, labels).item()  # Accumulate test loss\n",
    "\n",
    "        # Calculate test accuracy\n",
    "        test_accuracy = 100 * correct_test / total_test\n",
    "\n",
    "        # Calculate average test loss\n",
    "        test_loss /= len(test_loader)\n",
    "\n",
    "        # Record training and test loss and accuracy\n",
    "        train_losses.append(loss.item())\n",
    "        test_losses.append(test_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {loss.item():.4f}, Test Loss: {test_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Test Acc: {test_accuracy:.2f}%\")\n",
    "\n",
    "    # Append the accuracy and loss values for this fold to the respective lists\n",
    "    fold_train_accuracies.append(train_accuracies)\n",
    "    fold_test_accuracies.append(test_accuracies)\n",
    "    fold_train_losses.append(train_losses)\n",
    "    fold_test_losses.append(test_losses)\n",
    "\n",
    "# Plot loss and accuracy for each fold\n",
    "for fold in range(num_folds):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(fold_train_losses[fold], label=f'Fold {fold + 1} Train Loss')\n",
    "    plt.plot(fold_test_losses[fold], label=f'Fold {fold + 1} Test Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(fold_train_accuracies[fold], label=f'Fold {fold + 1} Train Accuracy')\n",
    "    plt.plot(fold_test_accuracies[fold], label=f'Fold {fold + 1} Test Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save the trained VGG model\n",
    "# torch.save(model.state_dict(), '5fold_resnet152_xray_classifier.pth')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image Classification Demo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5-fold validation VGG"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import KFold  # Import KFold for cross-validation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import random\n",
    "import matplotlib.pyplot as plt  # Import Matplotlib for plotting\n",
    "from torchvision.models import vgg19, VGG19_Weights\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# Create a KFold object to split the dataset\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracy and loss values for each fold\n",
    "fold_train_accuracies = []\n",
    "fold_test_accuracies = []\n",
    "fold_train_losses = []\n",
    "fold_test_losses = []\n",
    "\n",
    "for fold, (train_indices, test_indices) in enumerate(kf.split(dataset)):\n",
    "    print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "\n",
    "    # Split the dataset into train and test sets for this fold\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "    # Create data loaders for train and test sets\n",
    "    batch_size = 64\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    # VGG19\n",
    "    model = models.vgg19(weights=VGG19_Weights.DEFAULT)\n",
    "\n",
    "    # Modify the classifier part for your specific number of classes\n",
    "    model.classifier[6] = nn.Linear(4096, 2)  # output layer classes number = dataset classes number\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    # Lists to store loss and accuracy values\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    num_epochs = 25\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        correct_train = 0  # Correct predictions during training\n",
    "        total_train = 0    # Total examples during training\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            # Move images and labels to the selected device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate training accuracy within this batch\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = 100 * correct_train / total_train  # Calculate training accuracy\n",
    "\n",
    "        model.eval()\n",
    "        correct_test = 0   # Correct predictions during testing\n",
    "        total_test = 0     # Total examples during testing\n",
    "        test_loss = 0      # Variable to store test loss\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                # Move images and labels to the selected device\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "                test_loss += criterion(outputs, labels).item()  # Accumulate test loss\n",
    "\n",
    "        # Calculate test accuracy\n",
    "        test_accuracy = 100 * correct_test / total_test\n",
    "\n",
    "        # Calculate average test loss\n",
    "        test_loss /= len(test_loader)\n",
    "\n",
    "        # Record training and test loss and accuracy\n",
    "        train_losses.append(loss.item())\n",
    "        test_losses.append(test_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {loss.item():.4f}, Test Loss: {test_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Test Acc: {test_accuracy:.2f}%\")\n",
    "\n",
    "    # Append the accuracy and loss values for this fold to the respective lists\n",
    "    fold_train_accuracies.append(train_accuracies)\n",
    "    fold_test_accuracies.append(test_accuracies)\n",
    "    fold_train_losses.append(train_losses)\n",
    "    fold_test_losses.append(test_losses)\n",
    "\n",
    "# Plot loss and accuracy for each fold\n",
    "for fold in range(num_folds):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(fold_train_losses[fold], label=f'Fold {fold + 1} Train Loss')\n",
    "    plt.plot(fold_test_losses[fold], label=f'Fold {fold + 1} Test Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(fold_train_accuracies[fold], label=f'Fold {fold + 1} Train Accuracy')\n",
    "    plt.plot(fold_test_accuracies[fold], label=f'Fold {fold + 1} Test Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save the trained VGG model\n",
    "# torch.save(model.state_dict(), '5fold_vgg19_xray_classifier.pth')\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e04aa2904e12bb0da92c35f6c3111901f3911b03f5cb8f33364d8658f7b64f9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.17 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}