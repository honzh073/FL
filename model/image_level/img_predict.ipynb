{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Dataset (AFF and NFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on AFF images: 95.68%\n",
      "Accuracy on NFF images: 98.59%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['AFF', 'NFF']\n",
    "\n",
    "# Load the saved model\n",
    "model = models.resnet18(weights=None)  # Instantiate the ResNet18 model\n",
    "model.fc = nn.Linear(512, 2)  # Modify the output layer\n",
    "model.load_state_dict(torch.load('resnet18_xray_classifier.pth'))  # Load the trained weights\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define the image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image to 224x224 pixels\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n",
    "# Define the path to the directory containing your dataset\n",
    "dataset_path = '/local/data1/honzh073/model/data/8bit_dataset'  # Replace with the actual path\n",
    "\n",
    "# Create an ImageFolder dataset for the dataset\n",
    "dataset = ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "# Create a DataLoader for the dataset\n",
    "batch_size = 64\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize variables for accuracy calculation\n",
    "correct_aff = 0\n",
    "correct_nff = 0\n",
    "total_aff = 0\n",
    "total_nff = 0\n",
    "\n",
    "# Make predictions and calculate accuracy\n",
    "with torch.no_grad():\n",
    "    for images, labels in data_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted_class = outputs.max(1)\n",
    "        \n",
    "        # Calculate accuracy for AFF (class 0)\n",
    "        aff_indices = (predicted_class == 0).nonzero()\n",
    "        correct_aff += (predicted_class[aff_indices] == labels[aff_indices]).sum().item()\n",
    "        total_aff += aff_indices.size(0)\n",
    "        \n",
    "        # Calculate accuracy for NFF (class 1)\n",
    "        nff_indices = (predicted_class == 1).nonzero()\n",
    "        correct_nff += (predicted_class[nff_indices] == labels[nff_indices]).sum().item()\n",
    "        total_nff += nff_indices.size(0)\n",
    "\n",
    "# Calculate accuracy for AFF and NFF\n",
    "accuracy_aff = 100 * correct_aff / total_aff\n",
    "accuracy_nff = 100 * correct_nff / total_nff\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy on AFF images: {accuracy_aff:.2f}%\")\n",
    "print(f\"Accuracy on NFF images: {accuracy_nff:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Image Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: AFF\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['AFF', 'NFF']\n",
    "\n",
    "# Load the saved model\n",
    "model = models.resnet18(pretrained=False)  # Instantiate the ResNet18 model\n",
    "model.fc = nn.Linear(512, 2)  # Modify the output layer\n",
    "model.load_state_dict(torch.load('resnet18_xray_classifier.pth'))  # Load the trained weights\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define the image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image to 224x224 pixels\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n",
    "# Load and preprocess an input image\n",
    "# input_image_path = '/local/data1/honzh073/model/data/8bit_images/patient_BINZEEEHSR_hospital_55_AFF_image_4.png'\n",
    "input_image_path = '/local/data1/honzh073/model/data/8bit_images/patient_ZHAIJPEBDR_hospital_21_AFF_image_4.png'\n",
    "\n",
    "input_image = Image.open(input_image_path).convert('RGB')\n",
    "input_tensor = transform(input_image).unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "# Make a prediction\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "    _, predicted_class = output.max(1)\n",
    "\n",
    "# Get the predicted class label\n",
    "predicted_label = class_labels[predicted_class]\n",
    "\n",
    "# Print the result\n",
    "print(f\"Predicted Class: {predicted_label}\")\n",
    "\n",
    "# check this image must\n",
    "# /local/data1/honzh073/model/data/8bit_images/patient_ZHAIJPEBDR_hospital_21_AFF_image_4.png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e04aa2904e12bb0da92c35f6c3111901f3911b03f5cb8f33364d8658f7b64f9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.17 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
